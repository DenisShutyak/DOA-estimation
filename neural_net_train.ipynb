{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import  plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.callbacks\n",
    "import tensorflow.keras.losses\n",
    "import os\n",
    "import pydot\n",
    "os.chdir(r'C:\\Users\\densh\\Desktop\\catdogs\\keras_try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Parameters\n",
    "N_CLASSES = 2 # total number of classes\n",
    "IMG_HEIGHT = 320 # the image height to be resized to\n",
    "IMG_WIDTH = 320 # the image width to be resized to\n",
    "CHANNELS = 3 # The 3 color channels, change to 1 if grayscale\n",
    "initial_train_data = r'C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augmented_data'\n",
    "initial_validation = r'C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid'\n",
    "tf_train_data = r'C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augmented_data_tf'\n",
    "tf_validation = r'C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to plot nn graph\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files\\Graphviz\\bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Users\\densh\\AppData\\Roaming\\Python\\Python38\\Scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\n#rewriting darknet dataset to ft2 folder format\\n\\nwith open(os.path.join(tf_validation,'train_dataset.txt'),'w') as new_txt:\\n    for image in glob.glob(os.path.join(initial_validation,'*.jpg')):\\n        title, ext = os.path.splitext(os.path.basename(image))\\n        txt_file_name = title + '.txt'\\n        cv_image = cv2.imread(image)\\n        cv2.imwrite(tf_train_data + '/' + title + '.jpg',cv_image)\\n        with open(os.path.join(initial_validation,txt_file_name),'r') as old_txt:\\n            labelList = old_txt.readlines()\\n            for label in labelList:\\n                label = label.strip().split()\\n                class_ = int(label[0])\\n                x_c = float(label[1])\\n                y_c = float(label[2])\\n                h   = float(label[4])\\n                w   = float(label[3])\\n        \\n            new_txt.write(tf_validation + '/' + title + '.jpg' + '\\t' + str(int(label[0])) + '\\t' + str(x_c) \\n            + '\\t' + str(y_c) + '\\t' + str(w) + '\\t' + str(h) + '\\n')\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "'''\n",
    "#rewriting darknet dataset to ft2 folder format\n",
    "\n",
    "with open(os.path.join(tf_validation,'train_dataset.txt'),'w') as new_txt:\n",
    "    for image in glob.glob(os.path.join(initial_validation,'*.jpg')):\n",
    "        title, ext = os.path.splitext(os.path.basename(image))\n",
    "        txt_file_name = title + '.txt'\n",
    "        cv_image = cv2.imread(image)\n",
    "        cv2.imwrite(tf_train_data + '/' + title + '.jpg',cv_image)\n",
    "        with open(os.path.join(initial_validation,txt_file_name),'r') as old_txt:\n",
    "            labelList = old_txt.readlines()\n",
    "            for label in labelList:\n",
    "                label = label.strip().split()\n",
    "                class_ = int(label[0])\n",
    "                x_c = float(label[1])\n",
    "                y_c = float(label[2])\n",
    "                h   = float(label[4])\n",
    "                w   = float(label[3])\n",
    "        \n",
    "            new_txt.write(tf_validation + '/' + title + '.jpg' + '\\t' + str(int(label[0])) + '\\t' + str(x_c) \n",
    "            + '\\t' + str(y_c) + '\\t' + str(w) + '\\t' + str(h) + '\\n')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nimg_list = []\\nclass_list=[]\\nloc_list = []\\nfor image in glob.glob(os.path.join(tf_train_data,'*.jpg')):\\n    title, ext = os.path.splitext(os.path.basename(image))\\n    txt_file_name = title + '.txt'\\n    cv_image = cv2.imread(image)\\n    cv_image.resize(IMG_WIDTH,IMG_HEIGHT,3)\\n    with open(os.path.join(tf_train_data,txt_file_name),'r') as old_txt:\\n        labelList = old_txt.readlines()\\n        for label in labelList:\\n            label = label.strip().split()\\n            class_ = int(label[1])\\n            x_c = float(label[2])\\n            y_c = float(label[3])\\n            h     = float(label[5])\\n            w     = float(label[4])\\n    img_list.append(np.array(cv_image)/255)\\n    class_list.append(class_)\\n    loc_list.append([x_c,y_c,w,h])\\nimg_list = np.array(img_list)\\nclass_list =   np.array(class_list)\\nloc_list = np.array(loc_list)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "'''\n",
    "img_list = []\n",
    "class_list=[]\n",
    "loc_list = []\n",
    "for image in glob.glob(os.path.join(tf_train_data,'*.jpg')):\n",
    "    title, ext = os.path.splitext(os.path.basename(image))\n",
    "    txt_file_name = title + '.txt'\n",
    "    cv_image = cv2.imread(image)\n",
    "    cv_image.resize(IMG_WIDTH,IMG_HEIGHT,3)\n",
    "    with open(os.path.join(tf_train_data,txt_file_name),'r') as old_txt:\n",
    "        labelList = old_txt.readlines()\n",
    "        for label in labelList:\n",
    "            label = label.strip().split()\n",
    "            class_ = int(label[1])\n",
    "            x_c = float(label[2])\n",
    "            y_c = float(label[3])\n",
    "            h     = float(label[5])\n",
    "            w     = float(label[4])\n",
    "    img_list.append(np.array(cv_image)/255)\n",
    "    class_list.append(class_)\n",
    "    loc_list.append([x_c,y_c,w,h])\n",
    "img_list = np.array(img_list)\n",
    "class_list =   np.array(class_list)\n",
    "loc_list = np.array(loc_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   class       x_c       y_c         w         h  \\\n",
       "0      0  0.631667  0.287500  0.153333  0.215000   \n",
       "1      0  0.480000  0.396000  0.576000  0.372000   \n",
       "2      0  0.616751  0.338000  0.467005  0.392000   \n",
       "3      0  0.383249  0.662000  0.467005  0.392000   \n",
       "4      0  0.414444  0.432907  0.588889  0.635783   \n",
       "\n",
       "                                                file  \n",
       "0  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...  \n",
       "1  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...  \n",
       "2  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...  \n",
       "3  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...  \n",
       "4  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>x_c</th>\n      <th>y_c</th>\n      <th>w</th>\n      <th>h</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.631667</td>\n      <td>0.287500</td>\n      <td>0.153333</td>\n      <td>0.215000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.480000</td>\n      <td>0.396000</td>\n      <td>0.576000</td>\n      <td>0.372000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.616751</td>\n      <td>0.338000</td>\n      <td>0.467005</td>\n      <td>0.392000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.383249</td>\n      <td>0.662000</td>\n      <td>0.467005</td>\n      <td>0.392000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.414444</td>\n      <td>0.432907</td>\n      <td>0.588889</td>\n      <td>0.635783</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\augment...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "def parse_dataset(dataset_path, ext='jpg'):\n",
    "    \"\"\"\n",
    "    Used to extract information about our dataset. It does iterate over all images and return a DataFrame with\n",
    "    the data (age, gender and sex) of all files.\n",
    "    \"\"\"\n",
    "    def parse_info_from_file(path):\n",
    "        \"\"\"\n",
    "        Parse information from a single file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            title, ext = os.path.splitext(os.path.basename(path))\n",
    "            txt_file_name = title + '.txt'\n",
    "            with open(os.path.join(os.path.dirname(os.path.abspath(path)),txt_file_name),'r') as old_txt:\n",
    "                labelList = old_txt.readlines()\n",
    "                #print(str(labelList))\n",
    "                for label in labelList:\n",
    "                    label = label.strip().split()\n",
    "                    class_= int(label[1])\n",
    "                    x_c   = float(label[2])\n",
    "                    y_c   = float(label[3])\n",
    "                    w     = float(label[4])\n",
    "                    h     = float(label[5])\n",
    "            return class_, x_c, y_c, w, h\n",
    "        except Exception as ex:\n",
    "            return class_, None, None, None, None\n",
    "        \n",
    "    files = glob.glob(os.path.join(dataset_path, \"*.%s\" % ext))\n",
    "    \n",
    "    records = []\n",
    "    for file in files:\n",
    "        info = parse_info_from_file(file)\n",
    "        records.append(info)\n",
    "        \n",
    "    df = pd.DataFrame(records)\n",
    "    df['file'] = files\n",
    "    df.columns = ['class', 'x_c', 'y_c', 'w', 'h', 'file']\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = parse_dataset(tf_train_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   class       x_c       y_c         w         h  \\\n",
       "0      0  0.480480  0.233000  0.534535  0.294000   \n",
       "1      0  0.608000  0.277159  0.356000  0.426184   \n",
       "2      0  0.212000  0.253333  0.240000  0.389333   \n",
       "3      0  0.415916  0.336000  0.711712  0.440000   \n",
       "4      0  0.503125  0.273750  0.265000  0.367500   \n",
       "\n",
       "                                                file  \n",
       "0  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "1  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "2  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "3  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "4  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>x_c</th>\n      <th>y_c</th>\n      <th>w</th>\n      <th>h</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.480480</td>\n      <td>0.233000</td>\n      <td>0.534535</td>\n      <td>0.294000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.608000</td>\n      <td>0.277159</td>\n      <td>0.356000</td>\n      <td>0.426184</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.212000</td>\n      <td>0.253333</td>\n      <td>0.240000</td>\n      <td>0.389333</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.415916</td>\n      <td>0.336000</td>\n      <td>0.711712</td>\n      <td>0.440000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.503125</td>\n      <td>0.273750</td>\n      <td>0.265000</td>\n      <td>0.367500</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "val_df = parse_dataset(tf_validation)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    \"\"\"\n",
    "    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def generate_split_indexes(self):\n",
    "        p = np.random.permutation(len(self.df))\n",
    "        train_idx = p[:]\n",
    "        \n",
    "        return train_idx\n",
    "    \n",
    "    def generate_test_split_indexes(self,length):\n",
    "        p = np.random.randint(0,len(self.df),length)\n",
    "        train_idx = p[:]\n",
    "        \n",
    "        return train_idx\n",
    "    \n",
    "    def preprocess_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Used to perform some minor preprocessing on the image before inputting into the network.\n",
    "        \"\"\"\n",
    "        \n",
    "        im = Image.open(img_path)\n",
    "        im = im.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "        im = np.array(im) / 255.0\n",
    "        return im\n",
    "        \n",
    "    def generate_images(self, image_idx, is_training, batch_size):\n",
    "        \"\"\"\n",
    "        Used to generate a batch with images when training/testing/validating our Keras model.\n",
    "        \"\"\"\n",
    "        \n",
    "        # arrays to store our batched data\n",
    "        images, classes, x_c, y_c, w, h = [], [], [], [], [], []\n",
    "        while True:\n",
    "            for idx in image_idx:\n",
    "                imag = self.df.iloc[idx]\n",
    "                \n",
    "                classes_ = imag['class']\n",
    "                x_c_ = imag['x_c']\n",
    "                y_c_ = imag['y_c']\n",
    "                w_ = imag['w']\n",
    "                h_ = imag['h']\n",
    "                file = imag['file']\n",
    "                \n",
    "                im = self.preprocess_image(file)\n",
    "                \n",
    "                classes.append(classes_)\n",
    "                x_c.append(x_c_)\n",
    "                y_c.append(y_c_)\n",
    "                w.append(w_)\n",
    "                h.append(h_)\n",
    "                images.append(im)\n",
    "                #print(np.array(y_c))\n",
    "                # yielding condition\n",
    "                if len(images) >= batch_size:\n",
    "                    yield np.array(images), [np.array(to_categorical(classes,2)),(np.array(x_c),np.array(y_c), np.array(w), np.array(h))]\n",
    "                    images, classes, x_c, y_c, w, h = [], [], [], [], [], []\n",
    "                    \n",
    "            if not is_training:\n",
    "                break\n",
    "                \n",
    "data_generator = DataGenerator(df)\n",
    "train_idx = data_generator.generate_split_indexes() \n",
    "v_data_generator = DataGenerator(val_df)\n",
    "valid_idx = v_data_generator.generate_split_indexes() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS), name=\"img_input\")\n",
    "#classifier\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(block_3_output)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_4_output = layers.add([x, block_3_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_4_output)\n",
    "block_5_output = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_5_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_6_output = layers.add([x, block_5_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_6_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_7_output = layers.add([x, block_6_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_7_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_8_output = layers.add([x, block_7_output])\n",
    "\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(block_8_output)\n",
    "block_9_output = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(block_9_output)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_10_output = layers.add([x, block_9_output])\n",
    "\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(block_10_output)\n",
    "block_11_output = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "#x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(block_11_output)\n",
    "#x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "#block_12_output = layers.add([x, block_11_output])\n",
    "\n",
    "#x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(block_12_output)\n",
    "#x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "#block_13_output = layers.add([x, block_12_output])\n",
    "\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\")(block_7_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "def_set = layers.Dropout(0.2)(x)\n",
    "\n",
    "class_output = layers.Flatten()(def_set)\n",
    "class_output = layers.Dense(256, activation=\"relu\")(class_output)\n",
    "class_output = layers.Dense(128, activation=\"relu\")(class_output )\n",
    "class_output = layers.Dropout(0.2)(class_output )\n",
    "class_output = layers.Dense(64, activation=\"relu\")(class_output)\n",
    "class_output = layers.BatchNormalization()(class_output)\n",
    "class_output = layers.Dense(32, activation=\"relu\")(class_output)\n",
    "class_output = layers.Dense(2, activation=\"softmax\")(class_output)\n",
    "class_output = layers.Dense(2, activation=\"softmax\",name=\"class_output\")(class_output)\n",
    "#class_output = layers.Softmax(axis=-1,name=\"class_output\")(class_output)\n",
    "\n",
    "#Box\n",
    "Box_output = layers.Flatten()(block_11_output)\n",
    "Box_output = layers.Dense(256, activation=\"relu\")(Box_output)\n",
    "Box_output = layers.Dense(128, activation=\"relu\")(Box_output)\n",
    "Box_output = layers.Dropout(0.2)(Box_output )\n",
    "Box_output = layers.Dense(64, activation=\"relu\")(Box_output)\n",
    "Box_output = layers.Dropout(0.2)(Box_output )\n",
    "Box_output = layers.Dense(32, activation=\"relu\")(Box_output)\n",
    "Box_output = layers.Dense(4, activation='sigmoid', name= \"Box_output\")(Box_output)\n",
    "\n",
    "model2 = keras.Model(inputs, [class_output,Box_output], name=\"cats_dogs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model2,to_file='model.pdf',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 1e-2\n",
    "epochs = 50\n",
    "model2.compile(\n",
    "    optimizer=Adam(lr=init_lr, decay=init_lr / epochs),#tf.keras.optimizers.SGD(lr = 1e-2, momentum = 0.9),\n",
    "     loss={\n",
    "                  'Box_output': 'mean_squared_error',\n",
    "                  'class_output': 'categorical_crossentropy'},\n",
    "     loss_weights={\n",
    "                  'Box_output': 1,\n",
    "                  'class_output': 1},\n",
    "     metrics={\n",
    "        \"Box_output\": [\n",
    "            #keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError()],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "valid_batch_size = 24\n",
    "train_gen =   data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n",
    "valid_gen = v_data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(r\"C:\\Users\\densh\\Desktop\\catdogs\\keras_try\\Checkpoint\", monitor='val_loss'),\n",
    "    keras.callbacks.TensorBoard(\n",
    "    log_dir=r\"C:\\Users\\densh\\Desktop\\catdogs\\keras_try\\log\",write_images=True,\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\")  # How often to write logs (default: once per epoch)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can't send non-None value to a just-started generator",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a2339ea44fb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't send non-None value to a just-started generator"
     ]
    }
   ],
   "source": [
    "#np.shape(train_gen.send(1)[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      " 60/186 [========>.....................] - ETA: 53:07 - loss: 0.8526 - class_output_loss: 0.6089 - Box_output_loss: 0.2437 - class_output_categorical_accuracy: 0.7067 - Box_output_mean_absolute_error: 0.4668"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-fc7fe82b00bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mvalid_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.fit(train_gen,steps_per_epoch=len(train_idx)//(batch_size), callbacks=callbacks, epochs=epochs, validation_data=valid_gen, validation_steps=len(valid_idx)//valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\densh\\Desktop\\catdogs\\keras_try\\models\\assets\n"
     ]
    }
   ],
   "source": [
    "model2.save(\n",
    "    r\"C:\\Users\\densh\\Desktop\\catdogs\\keras_try\\models\",\n",
    "    overwrite=True, include_optimizer=True, save_format=None,\n",
    "    signatures=None, options=None, save_traces=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = v_data_generator.generate_test_split_indexes(10)\n",
    "test_gen =   v_data_generator.generate_images(train_idx, is_training=False, batch_size=1)\n",
    "c = model2.predict(test_gen,steps=len(train_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([[0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ],\n",
       "        [0.28716555, 0.7128345 ]], dtype=float32),\n",
       " array([[0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.]], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     class       x_c       y_c         w         h  \\\n",
       "307      0  0.590000  0.445333  0.172000  0.261333   \n",
       "146      1  0.537538  0.408000  0.828829  0.496000   \n",
       "171      1  0.421922  0.512000  0.501502  0.208000   \n",
       "96       1  0.470000  0.502667  0.364000  0.418667   \n",
       "269      0  0.484496  0.268000  0.589147  0.268000   \n",
       "378      1  0.577000  0.465333  0.366000  0.381333   \n",
       "123      0  0.536585  0.350000  0.650407  0.550000   \n",
       "341      1  0.442000  0.371212  0.712000  0.737374   \n",
       "283      1  0.450739  0.240000  0.625616  0.473333   \n",
       "262      1  0.552000  0.454955  0.500000  0.903904   \n",
       "\n",
       "                                                  file  \n",
       "307  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "146  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "171  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "96   C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "269  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "378  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "123  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "341  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "283  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  \n",
       "262  C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>x_c</th>\n      <th>y_c</th>\n      <th>w</th>\n      <th>h</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>307</th>\n      <td>0</td>\n      <td>0.590000</td>\n      <td>0.445333</td>\n      <td>0.172000</td>\n      <td>0.261333</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>1</td>\n      <td>0.537538</td>\n      <td>0.408000</td>\n      <td>0.828829</td>\n      <td>0.496000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>1</td>\n      <td>0.421922</td>\n      <td>0.512000</td>\n      <td>0.501502</td>\n      <td>0.208000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>0.470000</td>\n      <td>0.502667</td>\n      <td>0.364000</td>\n      <td>0.418667</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>269</th>\n      <td>0</td>\n      <td>0.484496</td>\n      <td>0.268000</td>\n      <td>0.589147</td>\n      <td>0.268000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>378</th>\n      <td>1</td>\n      <td>0.577000</td>\n      <td>0.465333</td>\n      <td>0.366000</td>\n      <td>0.381333</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>0</td>\n      <td>0.536585</td>\n      <td>0.350000</td>\n      <td>0.650407</td>\n      <td>0.550000</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>1</td>\n      <td>0.442000</td>\n      <td>0.371212</td>\n      <td>0.712000</td>\n      <td>0.737374</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>1</td>\n      <td>0.450739</td>\n      <td>0.240000</td>\n      <td>0.625616</td>\n      <td>0.473333</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>1</td>\n      <td>0.552000</td>\n      <td>0.454955</td>\n      <td>0.500000</td>\n      <td>0.903904</td>\n      <td>C:\\Users\\densh\\Desktop\\catdogs\\dataset\\valid_t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "val_df.iloc[train_idx,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ERROR: Could not find a version that satisfies the requirement cuDNN (from versions: none)\n",
      "ERROR: No matching distribution found for cuDNN\n"
     ]
    }
   ],
   "source": [
    "pip install cuDNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gtf.config.experimental.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd0184056108a3547f2193d2efa92fb0f74250f14e7b469048393661033d42ee1bf",
   "display_name": "Python 3.8.3 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}